import os
from openai import OpenAI
import logging
from pathlib import Path
from dotenv import load_dotenv
import argparse
from tqdm import tqdm
from collections import deque
from datetime import datetime, timedelta
import time
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from src.validator.arg_validator import validate_arguments
from src.helper.model_path_helper import resolve_model_name_for_path
from src.helper.cache_helper import check_and_load_cache
from src.helper.constants import get_extension_map, get_model_map
from src.translation.llm_prompts import (
    get_system_prompt_for_direct_translation,
    get_system_prompt_for_algorithm_based_translation,
    get_prompt_for_direct_translation,
    get_prompt_for_source_code_to_algorithm_generation,
    get_prompt_for_algorithm_to_code_translation
)
from src.helper.translation_helper import (
    get_algorithm_dir,
    get_translated_code_dir,
    refine_translated_code
)
from src.helper.io_helper import write_to_file, write_translation_data_to_xlsx

os.makedirs(f'logs', exist_ok=True)
logging.basicConfig(filename=f"logs/translation.log", level=logging.INFO, format='%(asctime)s %(levelname)s %(module)s - %(funcName)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

class Translator:
    def __init__(self, model, dataset) -> None:
        self.dataset = dataset
        self.base_url = os.getenv("BASE_URL")
        self.api_key = os.getenv("API_KEY")
        self.model = get_model_map().get(model)
        self.is_open_source_model = ":free" in self.model
        self.open_source_model_max_requests_per_minute = 20
        self.request_timestamps = deque()

    def __enter__(self):
        self.main_dir = os.getcwd()
        self.input_dir = Path(self.main_dir).joinpath("dataset", self.dataset)
        self.output_dir = os.path.join(self.main_dir, "output")

        if not self.input_dir.exists():
            logging.error(f"directory {str(self.input_dir)} does not exist. raising FileNotFoundError")
            raise FileNotFoundError(f"Directory {str(self.input_dir)} does not exist.")

        return self

    def wait_if_request_limit_reached(self):
        if not self.is_open_source_model:
            return

        current_time = datetime.now()
        cutoff_time = current_time - timedelta(minutes=1)
        while self.request_timestamps and self.request_timestamps[0] < cutoff_time:
            self.request_timestamps.popleft()

        if len(self.request_timestamps) >= self.open_source_model_max_requests_per_minute:
            time_to_wait = (self.request_timestamps[0] + timedelta(minutes=1) - current_time).total_seconds() + 1.0
            if time_to_wait > 0:
                logging.info(f"Per minute request limit reached for free model. Waiting for {time_to_wait:.2f} seconds...")

                time.sleep(time_to_wait)
                self.wait_if_request_limit_reached()
                return

        self.request_timestamps.append(current_time)

    def generate_response_using_llm(self, message_log):
        client = OpenAI(
            base_url=self.base_url,
            api_key=self.api_key,
        )

        response = "exceptional case"
        is_success = False
        max_attempts = 5
        while max_attempts > 0:
            try:
                self.wait_if_request_limit_reached()

                response = client.chat.completions.create(
                    model=self.model,
                    messages=message_log,
                    temperature=0.7,
                )
                is_success = True
                break
            except:
                max_attempts -= 1
                logging.info(f"Attempt {5 - max_attempts} failed. Retrying...")
                if max_attempts == 0:
                    logging.info("Maximum retry attempts reached")
                    raise

        if not is_success:
            return response

        return response.choices[0].message.content

    def get_algorithm_from_source_code(self, source_code_as_str, source_lang, message):
        logging.info(f"Generating algorithm from the given {source_lang} code using {self.model}")

        message.append({"role": "user", "content": get_prompt_for_source_code_to_algorithm_generation(source_code_as_str, source_lang)})
        
        response =  self.generate_response_using_llm(message)

        message.append({"role": "assistant", "content": response})

        return response
    
    def get_translated_code_from_algorithm(self, algorithm, target_lang, message):
        logging.info(f"Generating {target_lang} code with the algorithm generated by {self.model}")

        message.append({"role": "user", "content": get_prompt_for_algorithm_to_code_translation(algorithm, target_lang)})
        
        response = self.generate_response_using_llm(message)

        return response.replace(f"```{target_lang.lower()}", "").replace("```", "")
    
    def get_algorithm_based_translated_code(self, source_code_as_str, source_lang, target_lang):
        message = [{"role": "system", "content": get_system_prompt_for_algorithm_based_translation()}]

        algorithm = self.get_algorithm_from_source_code(source_code_as_str, source_lang, message)
        translated_code = self.get_translated_code_from_algorithm(algorithm, target_lang, message)

        return algorithm, translated_code
    
    def get_direct_translated_code(self, source_code_as_str, source_lang, target_lang):
        logging.info(f"Generating {target_lang} code based on the given {source_lang} code using {self.model}")

        message = [
            {"role": "system", "content": get_system_prompt_for_direct_translation()},
            {"role": "user", "content": get_prompt_for_direct_translation(source_code_as_str, source_lang, target_lang)}
        ]

        response = self.generate_response_using_llm(message)

        return response.replace(f"```{target_lang.lower()}", "").replace("```", "")

    def translate(self, source_lang, target_lang, is_algorithm_based_translation):
        snippets = list(self.input_dir.joinpath(source_lang.capitalize(), "Code").iterdir())

        translation_type_for_path = "algo_based_translation" if is_algorithm_based_translation else "direct_translation"
        model_name_for_path = resolve_model_name_for_path(self.model)
        base_dir_path = Path(self.output_dir).joinpath(model_name_for_path, self.dataset, translation_type_for_path, source_lang)

        logging.info(f"Executing {'algorithm-based' if is_algorithm_based_translation else 'direct'} source code translation")

        data = []
        for source_file in tqdm(snippets, total=len(snippets), bar_format="{desc:<5.5}{percentage:3.0f}%|{bar:10}{r_bar}"):
            source_code_id = source_file.stem
            source_code_as_str = source_file.read_text(encoding="utf-8")

            translated_code_dir = get_translated_code_dir(base_dir_path, target_lang)
            filename_of_translated_code = translated_code_dir.joinpath(f"{source_code_id}.{get_extension_map().get(target_lang)}")
            has_translated_code, cached_translated_code = check_and_load_cache(filename_of_translated_code)

            row_data = {"dataset": self.dataset, "model": self.model, "source_lang": source_lang, "target_lang": target_lang, "source_code_id": source_code_id, "source_code": source_code_as_str}

            if is_algorithm_based_translation:
                algorithm_dir = get_algorithm_dir(base_dir_path)
                filename_of_algorithm = algorithm_dir.joinpath(f"{source_code_id}.txt")
                has_algorithm, cached_algorithm = check_and_load_cache(filename_of_algorithm)

                if has_algorithm and has_translated_code:
                    logging.info(f"Algorithm and translated code already exists and using cache for {source_code_id}")
                    
                    row_data.update({
                        "algorithm": cached_algorithm,
                        "translated_code": cached_translated_code
                    })
                    data.append(row_data)
                    continue

                algorithm, translated_code = self.get_algorithm_based_translated_code(source_code_as_str, source_lang, target_lang)
                write_to_file(filename_of_algorithm, algorithm)
                
                row_data["algorithm"] = algorithm
            else:
                if has_translated_code:
                    logging.info(f"Translated code already exists and using cache for {source_code_id}")

                    row_data["translated_code"] = cached_translated_code
                    data.append(row_data)
                    continue
                
                translated_code = self.get_direct_translated_code(source_code_as_str, source_lang, target_lang)

            translated_code = refine_translated_code(self.dataset, translated_code, source_code_id, target_lang)
            write_to_file(filename_of_translated_code, translated_code)

            row_data["translated_code"] = translated_code
            data.append(row_data)

        xlsx_file_path = base_dir_path.joinpath(f"{translation_type_for_path}_{model_name_for_path}_{self.dataset}_{source_lang}_to_{target_lang}_translation_data.xlsx")
        columns = ["dataset", "model", "source_lang", "target_lang", "source_code_id", "source_code", "translated_code"]
        if is_algorithm_based_translation:
            columns.insert(6, "algorithm")

        write_translation_data_to_xlsx(xlsx_file_path, columns, data)
        
        logging.info("Translation process completed.")

    def __exit__(self, exception, _, __):
        print("Translation process completed successfully" if exception is None else f"Translation process failed due to {exception}")


if __name__ == "__main__":

    load_dotenv(override=True)

    parser = argparse.ArgumentParser()
    parser.add_argument("--model", help="model to use for code translation", required=True, type=str)
    parser.add_argument("--dataset", help="dataset to use for code translation", required=True, type=str)
    parser.add_argument("--source_lang", help="source language to use for code translation", required=True, type=str)
    parser.add_argument("--target_lang", help="target language to use for code translation", required=True, type=str)
    parser.add_argument("--translation_type", help="type of translation to use", required=True, type=str)
    
    args = parser.parse_args()
    validate_arguments(args)

    model = args.model
    dataset = args.dataset
    source_lang = args.source_lang
    target_lang = args.target_lang
    translation_type = args.translation_type

    is_algorithm_based_translation = translation_type == "algorithm"

    with Translator(model, dataset) as translator:
        logging.info(f"translating examples by {'algorithm-based approach' if is_algorithm_based_translation else 'direct approach'} with {model} from {source_lang} to {target_lang} using {dataset} dataset")
        translator.translate(source_lang, target_lang, is_algorithm_based_translation)
